{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "246d822a",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m1",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f769c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score, \n",
    "    roc_curve\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m2",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dawsklcy76m",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('churn_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m3",
   "metadata": {},
   "source": [
    "## 3. Prepare Train-Test Split\n",
    "\n",
    "Split the data into training (80%) and testing (20%) sets with stratification to maintain class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d915jt0eht",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "# Split into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Maintain class distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m4",
   "metadata": {},
   "source": [
    "## 4. Feature Scaling\n",
    "\n",
    "Neural networks require standardized features for optimal performance. We use StandardScaler to normalize all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wbkvz6sd89o",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m5",
   "metadata": {},
   "source": [
    "## 5. Define Model Architecture\n",
    "\n",
    "Build a neural network with hyperparameters that will be tuned through cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "y9cdvqv04hk",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim, learning_rate=0.0005, dropout_rate=0.4, l2_reg=0.001, hidden_size=256):\n",
    "    \"\"\"\n",
    "    Build neural network model with tunable hyperparameters.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        \n",
    "        # Hidden layer\n",
    "        layers.Dense(hidden_size, activation='relu', \n",
    "                     kernel_regularizer=keras.regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            keras.metrics.Precision(name='precision'),\n",
    "            keras.metrics.Recall(name='recall'),\n",
    "            keras.metrics.AUC(name='auc')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m6",
   "metadata": {},
   "source": [
    "## 6. Perform 5-Fold Cross-Validation\n",
    "\n",
    "Use cross-validation to find the best hyperparameters. SMOTE is applied inside each fold to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0gln4tzyb4mh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_nn(X, y, learning_rate, dropout_rate, l2_reg, batch_size, hidden_size, n_splits=5):\n",
    "    \"\"\"\n",
    "    Perform 5-fold cross-validation with SMOTE applied inside each fold.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_scores = {'precision': [], 'recall': [], 'auc': []}\n",
    "    \n",
    "    print(f\"\\nTesting: Hidden={hidden_size}, LR={learning_rate}, Dropout={dropout_rate}, L2={l2_reg}, Batch={batch_size}\")\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"  Fold {fold}/{n_splits}...\", end=\" \")\n",
    "        \n",
    "        # Split data\n",
    "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "        y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Apply SMOTE only to training fold\n",
    "        smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Build and train model\n",
    "        model = build_model(X_train_fold.shape[1], learning_rate, dropout_rate, l2_reg, hidden_size)\n",
    "        \n",
    "        early_stop = callbacks.EarlyStopping(monitor='loss', patience=10, \n",
    "                                             restore_best_weights=True, verbose=0)\n",
    "        \n",
    "        model.fit(X_train_balanced, y_train_balanced,\n",
    "                  epochs=50,\n",
    "                  batch_size=batch_size,\n",
    "                  callbacks=[early_stop],\n",
    "                  verbose=0)\n",
    "        \n",
    "        # Evaluate on validation fold\n",
    "        results = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        \n",
    "        # Store metrics (loss, accuracy, precision, recall, auc)\n",
    "        fold_scores['precision'].append(results[2])\n",
    "        fold_scores['recall'].append(results[3])\n",
    "        fold_scores['auc'].append(results[4])\n",
    "        \n",
    "        print(f\"Precision={results[2]:.4f}, Recall={results[3]:.4f}\")\n",
    "        \n",
    "        # Clean up\n",
    "        del model\n",
    "        keras.backend.clear_session()\n",
    "    \n",
    "    # Calculate averages\n",
    "    avg_scores = {metric: np.mean(scores) for metric, scores in fold_scores.items()}\n",
    "    std_scores = {metric: np.std(scores) for metric, scores in fold_scores.items()}\n",
    "    \n",
    "    return avg_scores, std_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j52enq0hxtm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter grid search with 5-fold cross-validation\n",
    "print(\"Parameter Grid\")\n",
    "\n",
    "hyperparameter_grid = [\n",
    "    {'lr': 0.001, 'dropout': 0.3, 'l2': 0.001, 'batch': 64, 'hidden': 256},\n",
    "    {'lr': 0.001, 'dropout': 0.4, 'l2': 0.001, 'batch': 64, 'hidden': 256},\n",
    "    {'lr': 0.0005, 'dropout': 0.3, 'l2': 0.001, 'batch': 64, 'hidden': 256},\n",
    "    {'lr': 0.001, 'dropout': 0.3, 'l2': 0.01, 'batch': 64, 'hidden': 256},\n",
    "    {'lr': 0.001, 'dropout': 0.3, 'l2': 0.001, 'batch': 128, 'hidden': 256},\n",
    "    {'lr': 0.001, 'dropout': 0.3, 'l2': 0.001, 'batch': 64, 'hidden': 512},\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal combinations to test: {len(hyperparameter_grid)}\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, params in enumerate(hyperparameter_grid, 1):\n",
    "    print(f\"\\n[Combination {i}/{len(hyperparameter_grid)}]\")\n",
    "    \n",
    "    avg_scores, std_scores = cross_validate_nn(\n",
    "        X_train_scaled, y_train,\n",
    "        params['lr'], params['dropout'], params['l2'], params['batch'], params['hidden'],\n",
    "        n_splits=5\n",
    "    )\n",
    "    \n",
    "    results.append({\n",
    "        'hidden_size': params['hidden'],\n",
    "        'learning_rate': params['lr'],\n",
    "        'dropout_rate': params['dropout'],\n",
    "        'l2_reg': params['l2'],\n",
    "        'batch_size': params['batch'],\n",
    "        'avg_precision': avg_scores['precision'],\n",
    "        'avg_recall': avg_scores['recall'],\n",
    "        'avg_auc': avg_scores['auc'],\n",
    "        'std_precision': std_scores['precision'],\n",
    "        'std_recall': std_scores['recall']\n",
    "    })\n",
    "    \n",
    "    print(f\"  → Avg Precision: {avg_scores['precision']:.4f} ± {std_scores['precision']:.4f}\")\n",
    "    print(f\"  → Avg Recall: {avg_scores['recall']:.4f} ± {std_scores['recall']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m7",
   "metadata": {},
   "source": [
    "## 7. Display Cross-Validation Results\n",
    "\n",
    "Show the best parameters found and the top parameter combinations based on precision score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv_results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display best parameters and cross-validation results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('avg_precision', ascending=False)\n",
    "\n",
    "print(\"\\nBest Parameters Found:\")\n",
    "best_params = results_df.iloc[0]\n",
    "print(f\"  hidden_size: {int(best_params['hidden_size'])}\")\n",
    "print(f\"  learning_rate: {best_params['learning_rate']}\")\n",
    "print(f\"  dropout_rate: {best_params['dropout_rate']}\")\n",
    "print(f\"  l2_reg: {best_params['l2_reg']}\")\n",
    "print(f\"  batch_size: {int(best_params['batch_size'])}\")\n",
    "\n",
    "print(f\"\\nBest Cross-Validation Precision Score: {best_params['avg_precision']:.4f}\")\n",
    "\n",
    "print(\"\\nTop 5 Parameter Combinations:\")\n",
    "for idx, row in results_df.head(5).iterrows():\n",
    "    print(f\"  Parameters: hidden={int(row['hidden_size'])}, lr={row['learning_rate']}, dropout={row['dropout_rate']}\")\n",
    "    print(f\"  CV Precision Score: {row['avg_precision']:.4f} (+/- {row['std_precision']:.4f})\")\n",
    "    print(f\"  CV Recall Score: {row['avg_recall']:.4f} (+/- {row['std_recall']:.4f})\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m8",
   "metadata": {},
   "source": [
    "## 8. Build and Train Final Model\n",
    "\n",
    "Train the final model using the best hyperparameters found via cross-validation. SMOTE is applied to the full training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cpxacoz3vmv",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to full training set\n",
    "smote_final = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_balanced, y_train_balanced = smote_final.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3yqiqf775dh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build final model with best hyperparameters\n",
    "model_final = build_model(\n",
    "    input_dim=X_train_scaled.shape[1],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    dropout_rate=best_params['dropout_rate'],\n",
    "    l2_reg=best_params['l2_reg'],\n",
    "    hidden_size=int(best_params['hidden_size'])\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal model architecture:\")\n",
    "print(f\"  Hidden layer size: {int(best_params['hidden_size'])} neurons\")\n",
    "print(f\"  Learning rate: {best_params['learning_rate']}\")\n",
    "print(f\"  Dropout rate: {best_params['dropout_rate']}\")\n",
    "print(f\"  L2 regularization: {best_params['l2_reg']}\")\n",
    "\n",
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2tq636s90a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model_final.fit(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    epochs=100,\n",
    "    batch_size=int(best_params['batch_size']),\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m9",
   "metadata": {},
   "source": [
    "## 9. Evaluate Model Performance\n",
    "\n",
    "Make predictions on the test set and calculate performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5s8cfqi2s1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred_proba = model_final.predict(X_test_scaled).flatten()\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"\\nNeural Network Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "# Calculate individual metrics\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"Performance Metrics\")\n",
    "print(f\"Precision:  {precision:.4f}\")\n",
    "print(f\"Recall:     {recall:.4f}\")\n",
    "print(f\"F1 Score:   {f1:.4f}\")\n",
    "print(f\"AUC-ROC:    {auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m10",
   "metadata": {},
   "source": [
    "## 10. Visualize Results\n",
    "\n",
    "Plot confusion matrix and ROC curve to visualize model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fn03kt9axfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix and ROC curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', ax=axes[0])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xticklabels(['No Churn', 'Churn'])\n",
    "axes[0].set_yticklabels(['No Churn', 'Churn'])\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "axes[1].plot(fpr, tpr, linewidth=2, label=f'ROC Curve (AUC = {auc_roc:.4f})', color='red')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "axes[1].set_title('ROC Curve', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate (Recall)')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
